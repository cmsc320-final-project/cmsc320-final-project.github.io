---
title: "Analyzing Goodreads' Readership"
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
library("tidyverse")
library("snakecase")
library("ggfortify")
library("cluster")
```

Goodreads is a social cataloging site where users can search, track, and rate books. The site has
over 20 million users, making it a large source of readership data. In this project,
we demonstrate how one can leverage this data using the Goodbooks-10k dataset [@goodbooks2017] to
do analysis on Goodread's readership by genre.

## Loading and Pre-processing Data

After being obtained,
the data can be easily loaded using R's `read.csv` method. For example, here we can load and display
`books.csv` to get a broad picture of one of the datasets we will be working
with. We can see that `books.csv` organizes its data in a tabulated manner with each book as a row
and the attributes of a book as columns.

```{r}
books_df <- read.csv("./goodbooks-10k/books.csv") %>%
  as_tibble()
head(books_df)
```

Let's load the rest of our data as well.

```{r}
ratings_df <- read.csv("./goodbooks-10k/ratings.csv")%>%
  as_tibble()
tags_df <- read.csv("./goodbooks-10k/tags.csv")%>%
  as_tibble()
book_tags_df <- read.csv("./goodbooks-10k/book_tags.csv")%>%
  as_tibble()
```

One of the things we are interested in is the genre of certain books.
We can narrow down the genres we are interested in with pipeline that
filters for certain genre names.

```{r}
tags_df <- tags_df %>%
  filter(tag_name %in% c(
    "fantasy",
    "mystery",
    "horror",
    "realistic-fiction",
    "romance",
    "science-fiction",
    "thriller",
    "young-adult"
  )) %>%
  as_tibble()

tags_df
```

However, this information is not very helpful by itself. We
want to be able to use it in conjunction with the other data
we have. One way to accomplish this is by joining data across
different datasets through a common attribute. Here, we construct a pipeline
to link data from `books_df` and `book_tags_df` through the shared
attribute, `goodreads_book_id`, and then `book_tags_df` and `tags_df`
through `tag_id`. We can see that `tag_name` does indeed describe
the genre of the books it's associated with.

```{r}
book_genres_df <- books_df %>%
  inner_join(book_tags_df, by="goodreads_book_id") %>%
  inner_join(tags_df, by="tag_id") %>%
  select("book_id", "title", "tag_name")

book_genres_df %>%
  select("title", "tag_name") %>%
  head(15)
```

Now we can use `book_genres_df` to try to figure out Goodreads readership.
Let's build another pipeline to join with `ratings_df` to link users
with the genres of the books they rated. We can do more data manipulation
from there to end up with a table of mean ratings in each genre of interest
for each users. The ratings range from 1 to 5. We also choose to designate
a mean rating of -5 to genres with no rating.

```{r}
# TODO: What should we replace na with??

# Note: This takes awhile to run...

user_features_raw_df <- ratings_df %>%
  inner_join(book_genres_df, by="book_id") %>%
  spread(tag_name, rating) %>%
  select(-book_id, -title,)

user_features_df <- user_features_raw_df %>%
  group_by(user_id) %>%
  summarize_all(mean, na.rm=TRUE) %>%
  select(-user_id,) %>%
  mutate_if(~ any(is.na(.x)),~ if_else(is.na(.x),-5,.x)) # Replace na with -5

# Convert column names to snake_case
colnames(user_features_df) = to_snake_case(colnames(user_features_df))

head(user_features_df, 15)
```

## Data Visualization and Analysis

One way we can better understand our data is through visualization.
For example, if we want to see where the readership lies on average
ratings for young adult and fantasy by plotting a 2D scatterplot. From the
graph, it appears most users are clustered from 3 to 5, and there is
not a strong overall preference for one genre versus the other. There are
also several users that appear to be readers of one
genre but not the other, and at least one user that
does not read from either.

```{r, fig.align='center'}
ggplot(user_features_df, mapping=aes(x=fantasy, y=young_adult)) +
  geom_point() +
  labs(
    title="User Average Ratings for Young Adult Versus Fantasy",
    x="Fantasy Rating",
    y="Young Adult Ratings"
  )
```

While the graph above is fine for comparing two genres, for comparing many genres
it becomes infeasible as it is hard visualize space beyond 3 dimensions. Furthermore,
we are also interested in clustering our data. While we had done a very cursory
grouping by eye-balling above, ideally, there should be a way to more formally
say which data points form a group with one another.

The solution to both of these problems is using a combination of **K-means clustering** to determine
groups of similar readers and **principle component analysis (PCA)** to reduce the dimensions of our
feature vectors for visualization in 2D space.

### Determining K

The main issue with using K-means is that we do not have a good idea of what is a "good" K. One way we can
address this is by doing several test runs with different K's and comparing them, specifically,
by comparing their total **sum of squared distances (SSE)**. Intuitively, a good clustering should
minimize the distances of points to the centroids of their respective clusters which would be reflected
in a low total SSE [@kmeansTDS].

While we want to lower variation within clusters, at the same time, we also want our clusters to actually be
clusters. This means that for any data point, it should ideally be close to the centroid of its cluster
and far from others, a metric known as the **silhouette** [@kmeansUCR]. While increasing K to an
unreasonably large number may reduce total SSE, data in such a clustering would have low silhouettes since data points in one
cluster would be very close to data points in other clusters.

The goal of finding a good K then resides in reducing SSE while still trying to keep silhouette high. Let's
compute and graph both SSE and silhouette from a sample of the users to see what a good K might be.

```{r, fig.align='center'}
set.seed(320)

k_range <- 2:20
user_features_sample_df <- sample_n(user_features_df, 1000)

# SSE
sse <- sapply(k_range, function(k) {
  kmeans(user_features_sample_df, k)$tot.withinss
})

ggplot(mapping=aes(x=k_range, y=sse)) +
  geom_line() +
  geom_label(aes(label=k_range)) + 
  labs(
    title="Total SSE vs K",
    x="k",
    y="Total SSE"
  )

# Average silhouettes
sil <- sapply(k_range, function(k) {
  km.res <- kmeans(user_features_sample_df, centers=k)
  ss <- silhouette(km.res$cluster, dist(user_features_sample_df))
  mean(ss[,3])
})

ggplot(mapping=aes(x=k_range, y=sil)) +
  geom_line() +
  geom_label(aes(label=k_range)) + 
  labs(
    title="Average Silhouettes vs K",
    x="k",
    y="Average Silhouette"
  )
```

Observing both graphs, K = 6 appears to be a point where total SSE has begun to flatten but
average silhouette is still somewhat high, making it a reasonable compromise for K. Let's try
to cluster all of our users with this K.

```{r, fig.align='center'}
set.seed(320)

kmeans_res <- kmeans(user_features_df, 6)
kmeans_res$centers

autoplot(kmeans_res, data=user_features_df, frame=TRUE) +
  labs(title="Readership Clusters")
```

**TODO: talk about clusters**

**TODO: Research and talk about pca**

## Predictions

```{r}
# TODO: cluster prediction (logistic regression? decision tree?)

training_data <- user_features_df %>%
  mutate(cluster=kmeans_res$cluster)

head(training_data, 15)
```

## Conclusion

**TODO: Write conclusion**

## References
